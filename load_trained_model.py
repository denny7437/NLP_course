#!/usr/bin/env python3
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class ReligiousDetector:
    def __init__(self, model_path="./religious_detector_manual"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.model.eval()
    
    def predict(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)
            prediction = torch.argmax(outputs.logits, dim=-1).item()
        
        return prediction, probs[0].numpy()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    detector = ReligiousDetector()
    
    examples = [
        "–†–µ–ª–∏–≥–∏—è –ø–æ–º–æ–≥–∞–µ—Ç –ª—é–¥—è–º –Ω–∞–π—Ç–∏ —Å–º—ã—Å–ª –∂–∏–∑–Ω–∏",
        "–í—Å–µ –≤–µ—Ä—É—é—â–∏–µ - –¥—É—Ä–∞–∫–∏ –∏ —Ñ–∞–Ω–∞—Ç–∏–∫–∏",
        "–î—É—Ö–æ–≤–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º–∏",
        "–¶–µ—Ä–∫–≤–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–∂–∂–µ–Ω—ã –¥–æ—Ç–ª–∞"
    ]
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:")
    for text in examples:
        pred, prob = detector.predict(text)
        class_name = "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if pred == 0 else "–û–ø–∞—Å–Ω—ã–π"
        confidence = prob[pred]
        
        print(f"\n–¢–µ–∫—Å—Ç: {text}")
        print(f"–ö–ª–∞—Å—Å: {class_name}")
        print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")
