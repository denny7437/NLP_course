#!/usr/bin/env python3
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π BERT –º–æ–¥–µ–ª–∏ —Å rule-based –ø–æ–¥—Ö–æ–¥–æ–º
"""

import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import time
import re
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class BERTDetector:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è BERT –º–æ–¥–µ–ª—å"""
    
    def __init__(self, model_path="./bert_religious_classifier_improved"):
        self.model_path = model_path
        self.tokenizer = None
        self.model = None
        self.max_length = 256
        
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é BERT –º–æ–¥–µ–ª—å –∏–∑ {self.model_path}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        self.model.eval()
        
        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è BERT –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        if self.model is None:
            self.load_model()
        
        predictions = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ CPU
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"üñ•Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        self.model.to(device)
        
        with torch.no_grad():
            for text in texts:
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    truncation=True,
                    padding='max_length',
                    max_length=self.max_length
                )
                
                inputs = {k: v.to(device) for k, v in inputs.items()}
                
                outputs = self.model(**inputs)
                predicted_class = torch.argmax(outputs.logits, dim=-1)
                predictions.append(predicted_class.item())
        
        return predictions


class RuleBasedDetector:
    """Rule-based –¥–µ—Ç–µ–∫—Ç–æ—Ä (—É–ª—É—á—à–µ–Ω–Ω—ã–π)"""
    
    def __init__(self):
        # –¢–µ –∂–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏
        self.dangerous_patterns = [
            # –ü—Ä—è–º—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è
            '–¥—É—Ä–∞–∫–∏', '–∏–¥–∏–æ—Ç—ã', '—Ç—É–ø—ã–µ', '–≥–ª—É–ø—ã–µ', '—Å–ª–∞–±–æ—É–º–Ω—ã–µ', '—Ñ–∞–Ω–∞—Ç–∏–∫–∏',
            '—Ä–∞–±—ã', '–∑–æ–º–±–∏', '–æ—Ç—Å—Ç–∞–ª—ã–µ', '–ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ', '–≤–∞—Ä–≤–∞—Ä—ã', '–¥–∏–∫–∞—Ä–∏',
            
            # –ü—Ä–∏–∑—ã–≤—ã –∫ –Ω–∞—Å–∏–ª–∏—é
            '—É–Ω–∏—á—Ç–æ–∂–∏—Ç—å', '—Å–∂–µ—á—å', '—É–±–∏—Ç—å', '—Å–º–µ—Ä—Ç—å', '—Å–æ–∂–∂–µ—Ç', '–≤—ã–∂–µ—á—å',
            '–∑–∞–ø—Ä–µ—â–µ–Ω–∞', '–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø—Ä–µ—â–µ–Ω–∞',
            
            # –û–±–≤–∏–Ω–µ–Ω–∏—è –≤ –æ–±–º–∞–Ω–µ
            '–ª–æ–∂—å', '–æ–±–º–∞–Ω', '–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ', '–ª–∂–∏–≤–∞—è', '—Å–∫–∞–∑–∫–∏', '—Ç–µ–∞—Ç—Ä',
            '–ª–∏—Ü–µ–º–µ—Ä–∏–µ', '–ª–∏—Ü–µ–º–µ—Ä–Ω—ã–π', '–ø—Ä–∏–∫—Ä—ã—Ç–∏–µ',
            
            # –°–µ–∫—Ç–∞–Ω—Ç—Å–∫–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
            '—Å–µ–∫—Ç–∞', '—Å–µ–∫—Ç–∞–Ω—Ç—ã', '–ø—Ä–æ–º—ã–≤–∞–Ω–∏–µ –º–æ–∑–≥–æ–≤', '–∑–æ–º–±–∏—Ä—É—é—Ç', '–∫—É–ª—å—Ç',
            '—Ç–æ—Ç–∞–ª–∏—Ç–∞—Ä–Ω–∞—è —Å–µ–∫—Ç–∞', '—Ä–∞–±–æ–≤–µ—Ä—É—é—â–∏—Ö',
            
            # –†–∞–¥–∏–∫–∞–ª—å–Ω—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è
            '—á—É–º–∞', '–≤–∏—Ä—É—Å', '–æ—Ç—Ä–∞–≤–ª—è–µ—Ç', '—Ä–∞–∫–æ–≤–∞—è –æ–ø—É—Ö–æ–ª—å', '–ø–∞—Ä–∞–∑–∏—Ç',
            '–ø—Å–∏—Ö–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', '–∫–∞–ª–µ—á–∞—â–∏–π –ø—Å–∏—Ö–∏–∫—É',
            
            # –ê–Ω—Ç–∏—Ä–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è –∞–≥—Ä–µ—Å—Å–∏—è
            '–≤—ã–∑–¥–æ—Ä–æ–≤–µ–µ—Ç, —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞', '–ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ—Ä–∫–æ–≤—å', '–ø–æ—Å–ª–µ–¥–Ω—é—é –±–∏–±–ª–∏—é'
        ]
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª"""
        predictions = []
        
        for text in texts:
            text_lower = text.lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø–∞—Å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            is_dangerous = any(pattern in text_lower for pattern in self.dangerous_patterns)
            
            if is_dangerous:
                predictions.append(1)  # –û–ø–∞—Å–Ω—ã–π
            else:
                predictions.append(0)  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π
        
        return predictions


def evaluate_model(model, test_texts, test_labels, model_name):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
    logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É—é {model_name}...")
    
    start_time = time.time()
    predictions = model.predict(test_texts)
    end_time = time.time()
    
    prediction_time = end_time - start_time
    logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {prediction_time:.3f} —Å–µ–∫—É–Ω–¥")
    logger.info(f"üî¢ –ü–æ–ª—É—á–µ–Ω–æ {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(test_labels, predictions)
    report = classification_report(
        test_labels,
        predictions,
        target_names=['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', '–û–ø–∞—Å–Ω—ã–π'],
        output_dict=True
    )
    
    cm = confusion_matrix(test_labels, predictions)
    
    return {
        'predictions': predictions,
        'accuracy': accuracy,
        'report': report,
        'confusion_matrix': cm,
        'prediction_time': prediction_time
    }


def print_results(results, model_name):
    """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    logger.info(f"\nüéØ {model_name}:")
    logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {results['accuracy']:.3f} ({results['accuracy']*100:.1f}%)")
    logger.info(f"   –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {results['prediction_time']:.3f} —Å–µ–∫")
    
    report = results['report']
    logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
    logger.info(f"     Precision: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
    logger.info(f"     Recall: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
    logger.info(f"     F1-score: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
    
    logger.info(f"   –û–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
    logger.info(f"     Precision: {report['–û–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
    logger.info(f"     Recall: {report['–û–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
    logger.info(f"     F1-score: {report['–û–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
    
    cm = results['confusion_matrix']
    logger.info(f"   –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
    logger.info(f"              –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
    logger.info(f"          –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π  –û–ø–∞—Å–Ω—ã–π")
    logger.info(f"   –ò—Å—Ç–∏–Ω–Ω–æ")
    logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π    {cm[0,0]:3d}       {cm[0,1]:3d}")
    logger.info(f"   –û–ø–∞—Å–Ω—ã–π       {cm[1,0]:3d}       {cm[1,1]:3d}")


def create_labels(texts):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    logger.info("üè∑Ô∏è –°–æ–∑–¥–∞—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ä–∞–∑–º–µ—Ç–∫—É...")
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø–∞—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    dangerous_patterns = [
        # –ü—Ä—è–º—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è
        '–¥—É—Ä–∞–∫–∏', '–∏–¥–∏–æ—Ç—ã', '—Ç—É–ø—ã–µ', '–≥–ª—É–ø—ã–µ', '—Å–ª–∞–±–æ—É–º–Ω—ã–µ', '—Ñ–∞–Ω–∞—Ç–∏–∫–∏',
        '—Ä–∞–±—ã', '–∑–æ–º–±–∏', '–æ—Ç—Å—Ç–∞–ª—ã–µ', '–ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ', '–≤–∞—Ä–≤–∞—Ä—ã', '–¥–∏–∫–∞—Ä–∏',
        
        # –ü—Ä–∏–∑—ã–≤—ã –∫ –Ω–∞—Å–∏–ª–∏—é
        '—É–Ω–∏—á—Ç–æ–∂–∏—Ç—å', '—Å–∂–µ—á—å', '—É–±–∏—Ç—å', '—Å–º–µ—Ä—Ç—å', '—Å–æ–∂–∂–µ—Ç', '–≤—ã–∂–µ—á—å',
        '–∑–∞–ø—Ä–µ—â–µ–Ω–∞', '–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø—Ä–µ—â–µ–Ω–∞',
        
        # –û–±–≤–∏–Ω–µ–Ω–∏—è –≤ –æ–±–º–∞–Ω–µ
        '–ª–æ–∂—å', '–æ–±–º–∞–Ω', '–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ', '–ª–∂–∏–≤–∞—è', '—Å–∫–∞–∑–∫–∏', '—Ç–µ–∞—Ç—Ä',
        '–ª–∏—Ü–µ–º–µ—Ä–∏–µ', '–ª–∏—Ü–µ–º–µ—Ä–Ω—ã–π', '–ø—Ä–∏–∫—Ä—ã—Ç–∏–µ',
        
        # –°–µ–∫—Ç–∞–Ω—Ç—Å–∫–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
        '—Å–µ–∫—Ç–∞', '—Å–µ–∫—Ç–∞–Ω—Ç—ã', '–ø—Ä–æ–º—ã–≤–∞–Ω–∏–µ –º–æ–∑–≥–æ–≤', '–∑–æ–º–±–∏—Ä—É—é—Ç', '–∫—É–ª—å—Ç',
        '—Ç–æ—Ç–∞–ª–∏—Ç–∞—Ä–Ω–∞—è —Å–µ–∫—Ç–∞', '—Ä–∞–±–æ–≤–µ—Ä—É—é—â–∏—Ö',
        
        # –†–∞–¥–∏–∫–∞–ª—å–Ω—ã–µ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è
        '—á—É–º–∞', '–≤–∏—Ä—É—Å', '–æ—Ç—Ä–∞–≤–ª—è–µ—Ç', '—Ä–∞–∫–æ–≤–∞—è –æ–ø—É—Ö–æ–ª—å', '–ø–∞—Ä–∞–∑–∏—Ç',
        '–ø—Å–∏—Ö–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', '–∫–∞–ª–µ—á–∞—â–∏–π –ø—Å–∏—Ö–∏–∫—É',
        
        # –ê–Ω—Ç–∏—Ä–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è –∞–≥—Ä–µ—Å—Å–∏—è
        '–≤—ã–∑–¥–æ—Ä–æ–≤–µ–µ—Ç, —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞', '–ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ—Ä–∫–æ–≤—å', '–ø–æ—Å–ª–µ–¥–Ω—é—é –±–∏–±–ª–∏—é'
    ]
    
    labels = []
    dangerous_count = 0
    
    for text in texts:
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–ø–∞—Å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        is_dangerous = any(pattern in text_lower for pattern in dangerous_patterns)
        
        if is_dangerous:
            labels.append(1)  # –û–ø–∞—Å–Ω—ã–π
            dangerous_count += 1
        else:
            labels.append(0)  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π
    
    safe_count = len(texts) - dangerous_count
    logger.info(f"üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞:")
    logger.info(f"   ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö: {safe_count} ({safe_count/len(texts)*100:.1f}%)")
    logger.info(f"   üö® –û–ø–∞—Å–Ω—ã—Ö: {dangerous_count} ({dangerous_count/len(texts)*100:.1f}%)")
    
    return labels


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üéØ –°–†–ê–í–ù–ï–ù–ò–ï –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ô BERT –ú–û–î–ï–õ–ò –° RULE-BASED –ü–û–î–•–û–î–û–ú")
    logger.info("=" * 65)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        logger.info(f"üöÄ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_name}")
        logger.info(f"üíæ –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        logger.info("üñ•Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU")
    
    logger.info("üìÇ –ó–∞–≥—Ä—É–∂–∞—é –∏—Å—Ö–æ–¥–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv("eval_modernbert - –õ–∏—Å—Ç1.csv")
    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    test_texts = df['text'].tolist()
    
    # –°–æ–∑–¥–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ä–∞–∑–º–µ—Ç–∫—É
    test_labels = create_labels(test_texts)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    labeled_df = pd.DataFrame({
        'text': test_texts,
        'label': test_labels
    })
    labeled_df.to_csv("eval_modernbert_auto_labeled.csv", index=False)
    logger.info("üíæ –†–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ eval_modernbert_auto_labeled.csv")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    logger.info("\nüìä –ê–ù–ê–õ–ò–ó –¢–ï–°–¢–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    logger.info("=" * 35)
    logger.info(f"üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(test_texts)}")
    
    safe_count = sum(1 for label in test_labels if label == 0)
    dangerous_count = sum(1 for label in test_labels if label == 1)
    
    logger.info(f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö (label=0): {safe_count} ({safe_count/len(test_labels)*100:.1f}%)")
    logger.info(f"üö® –û–ø–∞—Å–Ω—ã—Ö (label=1): {dangerous_count} ({dangerous_count/len(test_labels)*100:.1f}%)")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    logger.info("\nüÜö –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    logger.info("=" * 25)
    
    bert_model = BERTDetector()
    rule_model = RuleBasedDetector()
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    bert_results = evaluate_model(bert_model, test_texts, test_labels, "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è BERT –º–æ–¥–µ–ª—å")
    rule_results = evaluate_model(rule_model, test_texts, test_labels, "Rule-based –º–æ–¥–µ–ª—å")
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø")
    logger.info("=" * 30)
    
    print_results(bert_results, "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è BERT –º–æ–¥–µ–ª—å")
    print_results(rule_results, "Rule-based –º–æ–¥–µ–ª—å")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
    bert_preds = bert_results['predictions']
    rule_preds = rule_results['predictions']
    
    agreement = sum(1 for i in range(len(bert_preds)) if bert_preds[i] == rule_preds[i])
    agreement_rate = agreement / len(bert_preds)
    
    logger.info(f"\nü§ù –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π:")
    logger.info(f"   –°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {agreement}/{len(bert_preds)} ({agreement_rate*100:.1f}%)")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π
    disagreements = []
    for i in range(len(bert_preds)):
        if bert_preds[i] != rule_preds[i]:
            disagreements.append((i, test_texts[i], bert_preds[i], rule_preds[i], test_labels[i]))
    
    if disagreements:
        logger.info(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 5):")
        for idx, (i, text, bert_pred, rule_pred, true_label) in enumerate(disagreements[:5], 1):
            bert_name = "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if bert_pred == 0 else "–û–ø–∞—Å–Ω—ã–π"
            rule_name = "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if rule_pred == 0 else "–û–ø–∞—Å–Ω—ã–π"
            true_name = "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if true_label == 0 else "–û–ø–∞—Å–Ω—ã–π"
            
            logger.info(f"   {idx}. '{text[:70]}{'...' if len(text) > 70 else ''}'")
            logger.info(f"      BERT: {bert_name}, Rule: {rule_name} (–∏—Å—Ç–∏–Ω–∞: {true_name})")
    
    # –ö–∞–∫–∞—è –º–æ–¥–µ–ª—å –ª—É—á—à–µ?
    if bert_results['accuracy'] > rule_results['accuracy']:
        winner = "BERT –º–æ–¥–µ–ª—å"
        advantage = bert_results['accuracy'] - rule_results['accuracy']
    elif rule_results['accuracy'] > bert_results['accuracy']:
        winner = "Rule-based –º–æ–¥–µ–ª—å"
        advantage = rule_results['accuracy'] - bert_results['accuracy']
    else:
        winner = "–ù–∏—á—å—è"
        advantage = 0
    
    logger.info(f"\nüèÜ –ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
    if winner != "–ù–∏—á—å—è":
        logger.info(f"   –ü–æ–±–µ–¥–∏—Ç–µ–ª—å: {winner}")
        logger.info(f"   –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏: {advantage:.3f} ({advantage*100:.1f}%)")
    else:
        logger.info(f"   –û–±–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—É—é —Ç–æ—á–Ω–æ—Å—Ç—å!")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    logger.info(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if bert_results['accuracy'] > 0.9:
        logger.info("   ‚úÖ BERT –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    if rule_results['accuracy'] > 0.9:
        logger.info("   ‚úÖ Rule-based –ø–æ–¥—Ö–æ–¥ –æ—á–µ–Ω—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω")
    if rule_results['prediction_time'] < bert_results['prediction_time']:
        logger.info("   ‚ö° Rule-based –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ")
    if agreement_rate > 0.9:
        logger.info("   ü§ù –í—ã—Å–æ–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π - —Ö–æ—Ä–æ—à–∏–π –∑–Ω–∞–∫")
    
    logger.info("\nüéâ –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    logger.info("‚ú® –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –¥–≤–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏!")


if __name__ == "__main__":
    main() 