#!/usr/bin/env python3
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —á—É–≤—Å—Ç–≤ –≤–µ—Ä—É—é—â–∏—Ö
–Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ eval_modernbert - –õ–∏—Å—Ç1.csv
"""

import pandas as pd
import numpy as np
import subprocess
import os
import sys
import time
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ModelTester:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, model_path):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.max_length = 512
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å –∏–∑ {self.model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_path)
            self.model.eval()
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤"""
        predictions = []
        
        logger.info(f"üîÆ –î–µ–ª–∞—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...")
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU
        device = torch.device('cpu')
        self.model.to(device)
        
        with torch.no_grad():
            for i, text in enumerate(texts):
                if i % 100 == 0:
                    logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(texts)}")
                
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    truncation=True,
                    padding='max_length',
                    max_length=self.max_length
                )
                
                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ CPU
                inputs = {k: v.to(device) for k, v in inputs.items()}
                
                outputs = self.model(**inputs)
                predicted_class = torch.argmax(outputs.logits, dim=-1)
                predictions.append(predicted_class.item())
        
        logger.info("‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω—ã")
        return predictions


def run_training_script(script_name):
    """–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –æ–±—É—á–µ–Ω–∏—è"""
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é –æ–±—É—á–µ–Ω–∏–µ: {script_name}")
    
    try:
        result = subprocess.run([
            sys.executable, script_name
        ], capture_output=True, text=True, timeout=3600)  # 1 —á–∞—Å timeout
        
        if result.returncode == 0:
            logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ {script_name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            logger.info("–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤—ã–≤–æ–¥–∞:")
            for line in result.stdout.split('\n')[-10:]:
                if line.strip():
                    logger.info(f"   {line}")
            return True
        else:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ {script_name}:")
            logger.error(f"   Stdout: {result.stdout}")
            logger.error(f"   Stderr: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error(f"‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω timeout –¥–ª—è {script_name}")
        return False
    except Exception as e:
        logger.error(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ {script_name}: {e}")
        return False


def analyze_test_dataset(df):
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    logger.info("üìä –ê–ù–ê–õ–ò–ó –¢–ï–°–¢–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    logger.info("="*50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ label
    if 'label' not in df.columns:
        logger.warning("‚ö†Ô∏è –í —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 'label'")
        logger.info("üîç –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:", list(df.columns))
        return False
    
    total_samples = len(df)
    safe_count = (df['label'] == 0).sum() if 'label' in df.columns else 0
    dangerous_count = (df['label'] == 1).sum() if 'label' in df.columns else 0
    
    logger.info(f"üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {total_samples}")
    if 'label' in df.columns:
        logger.info(f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö (label=0): {safe_count} ({safe_count/total_samples*100:.1f}%)")
        logger.info(f"üö® –û–ø–∞—Å–Ω—ã—Ö (label=1): {dangerous_count} ({dangerous_count/total_samples*100:.1f}%)")
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤
    text_lengths = df['text'].str.len()
    word_counts = df['text'].str.split().str.len()
    
    logger.info(f"\nüìù –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤:")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {text_lengths.mean():.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"   –ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: {text_lengths.median():.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Å–ª–æ–≤: {word_counts.mean():.1f}")
    
    # –ü—Ä–∏–º–µ—Ä—ã
    logger.info(f"\nüîç –ü–µ—Ä–≤—ã–µ 3 –ø—Ä–∏–º–µ—Ä–∞:")
    for i, text in enumerate(df['text'].head(3), 1):
        label_info = f" (label={df.iloc[i-1]['label']})" if 'label' in df.columns else ""
        logger.info(f"   {i}.{label_info} {text}")
    
    logger.info("="*50)
    return True


def compare_models(test_df):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π"""
    logger.info("üÜö –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    logger.info("="*50)
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    simple_model_path = "./temp_religious_classifier"  # –∏–∑ train_religious_detector_simple.py
    final_model_path = "./religious_content_detector_final"  # –∏–∑ train_final_model.py
    
    models_info = {
        "–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å": {
            "path": simple_model_path,
            "script": "train_religious_detector_simple.py"
        },
        "–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å": {
            "path": final_model_path,
            "script": "train_final_model.py"
        }
    }
    
    results = {}
    texts = test_df['text'].tolist()
    true_labels = test_df['label'].tolist() if 'label' in test_df.columns else None
    
    for model_name, model_info in models_info.items():
        logger.info(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É—é {model_name}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if not os.path.exists(model_info["path"]):
            logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏ {model_info['path']}")
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫–∞—é –æ–±—É—á–µ–Ω–∏–µ...")
            
            if not run_training_script(model_info["script"]):
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å {model_name}")
                continue
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        tester = ModelTester(model_info["path"])
        if not tester.load_model():
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_name}")
            continue
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        start_time = time.time()
        predictions = tester.predict(texts)
        prediction_time = time.time() - start_time
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results[model_name] = {
            "predictions": predictions,
            "prediction_time": prediction_time,
            "model_path": model_info["path"]
        }
        
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {prediction_time:.2f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üî¢ –ü–æ–ª—É—á–µ–Ω–æ {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if true_labels and len(results) >= 2:
        logger.info("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        logger.info("="*50)
        
        for model_name, model_results in results.items():
            predictions = model_results["predictions"]
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(true_labels, predictions)
            
            logger.info(f"\nüéØ {model_name}:")
            logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f} ({accuracy*100:.1f}%)")
            logger.info(f"   –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {model_results['prediction_time']:.2f} —Å–µ–∫")
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            report = classification_report(
                true_labels, 
                predictions, 
                target_names=['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', '–û–ø–∞—Å–Ω—ã–π'],
                output_dict=True
            )
            
            logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
            logger.info(f"     Precision: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
            logger.info(f"     Recall: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
            logger.info(f"     F1-score: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
            
            logger.info(f"   –û–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
            logger.info(f"     Precision: {report['–û–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
            logger.info(f"     Recall: {report['–û–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
            logger.info(f"     F1-score: {report['–û–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
            
            # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            cm = confusion_matrix(true_labels, predictions)
            logger.info(f"   –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
            logger.info(f"              –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
            logger.info(f"          –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π  –û–ø–∞—Å–Ω—ã–π")
            logger.info(f"   –ò—Å—Ç–∏–Ω–Ω–æ")
            logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π    {cm[0,0]:3d}      {cm[0,1]:3d}")
            logger.info(f"   –û–ø–∞—Å–Ω—ã–π       {cm[1,0]:3d}      {cm[1,1]:3d}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
    if len(results) >= 2:
        model_names = list(results.keys())
        predictions1 = results[model_names[0]]["predictions"]
        predictions2 = results[model_names[1]]["predictions"]
        
        agreement = sum(p1 == p2 for p1, p2 in zip(predictions1, predictions2))
        agreement_rate = agreement / len(predictions1)
        
        logger.info(f"\nü§ù –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π:")
        logger.info(f"   –°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {agreement}/{len(predictions1)} ({agreement_rate*100:.1f}%)")
        
        # –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π
        disagreements = []
        for i, (p1, p2) in enumerate(zip(predictions1, predictions2)):
            if p1 != p2:
                disagreements.append({
                    "index": i,
                    "text": texts[i],
                    model_names[0]: "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if p1 == 0 else "–û–ø–∞—Å–Ω—ã–π",
                    model_names[1]: "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if p2 == 0 else "–û–ø–∞—Å–Ω—ã–π",
                    "true_label": "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if true_labels[i] == 0 else "–û–ø–∞—Å–Ω—ã–π" if true_labels else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                })
        
        if disagreements:
            logger.info(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 5):")
            for i, disagreement in enumerate(disagreements[:5], 1):
                logger.info(f"   {i}. '{disagreement['text']}'")
                logger.info(f"      {disagreement[model_names[0]]} vs {disagreement[model_names[1]]} (–∏—Å—Ç–∏–Ω–∞: {disagreement['true_label']})")
    
    return results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üéØ –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–ï–¢–ï–ö–¶–ò–ò –û–°–ö–û–†–ë–õ–ï–ù–ò–Ø –ß–£–í–°–¢–í –í–ï–†–£–Æ–©–ò–•")
    logger.info("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_file = "eval_modernbert - –õ–∏—Å—Ç1.csv"
    labeled_test_file = "eval_modernbert_labeled - –õ–∏—Å—Ç1.csv"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    if not os.path.exists(labeled_test_file):
        logger.info("üìù –†–∞–∑–º–µ—á–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—é —Ä–∞–∑–º–µ—Ç–∫—É...")
        try:
            result = subprocess.run([sys.executable, "label_test_data.py"], 
                                  capture_output=True, text=True, timeout=60)
            if result.returncode != 0:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–∞–∑–º–µ—Ç–∫–∏: {result.stderr}")
                return
            logger.info("‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Ä–∞–∑–º–µ—Ç–∫–∏: {e}")
            return
    
    try:
        logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ {labeled_test_file}...")
        test_df = pd.read_csv(labeled_test_file)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_df)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    except FileNotFoundError:
        logger.error(f"‚ùå –§–∞–π–ª {labeled_test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {labeled_test_file}: {e}")
        return
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not analyze_test_dataset(test_df):
        logger.error("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º")
        return
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    results = compare_models(test_df)
    
    if results:
        logger.info("\nüéâ –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        logger.info("‚ú® –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥–∞—Ö –≤—ã—à–µ")
    else:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏")


if __name__ == "__main__":
    main() 