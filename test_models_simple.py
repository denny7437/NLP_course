#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —á—É–≤—Å—Ç–≤ –≤–µ—Ä—É—é—â–∏—Ö
—Å –∏–º–∏—Ç–∞—Ü–∏–µ–π —Ä–∞–±–æ—Ç—ã –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
"""

import pandas as pd
import numpy as np
import re
import time
import logging
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class SimpleRuleBasedDetector:
    """–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª"""
    
    def __init__(self, name="–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å"):
        self.name = name
        self.dangerous_keywords = [
            '—Ñ–∞–Ω–∞—Ç–∏–∫', '—Å–µ–∫—Ç–∞', '–ª–æ–∂—å', '–æ–±–º–∞–Ω', '–ª–∏—Ü–µ–º–µ—Ä', '–æ–ø–∏—É–º', 
            '—á—É–º–∞', '–æ—Ç—Ä–∞–≤–ª—è', '—É–Ω–∏—á—Ç–æ–∂', '—Å–æ–∂–∂', '–¥–æ–ª–æ–π', '–≤—Ä–∞–≥',
            '–Ω–µ–Ω–∞–≤–∏—Å—Ç', '—É–±–∏–≤–∞', '–ø–∞—Ä–∞–∑–∏—Ç', '—Ä–∞–±—ã', '–∑–æ–º–±–∏—Ä', '—Ç–µ—Ä—Ä–æ—Ä',
            '—Ä–µ–ø—Ä–µ—Å—Å–∏', '—Å–∞–¥–∏—Å—Ç', '–ø—Ä–æ—Ç–∏–≤', '—Ç–æ—Ç–∞–ª–∏—Ç–∞—Ä'
        ]
        
        self.safe_keywords = [
            '–º–æ–ª–∏—Ç–≤–∞', '–±–ª–∞–≥–æ—Å–ª–æ–≤', '–≤–µ—Ä–∞', '–ª—é–±–æ–≤—å', '–º–∏—Ä', '–Ω–∞–¥–µ–∂–¥–∞',
            '—É—Ç–µ—à–µ–Ω–∏–µ', '–º—É–¥—Ä–æ—Å—Ç—å', '–¥–æ–±—Ä–æ—Ç–∞', '–º–∏–ª–æ—Å–µ—Ä–¥–∏–µ', '–ø—Ä–æ—â–µ–Ω–∏–µ',
            '–¥—É—Ö–æ–≤–Ω', '–ø–æ–∫–æ–π', '—á—É–¥–µ—Å–∞', '—Å–≤—è—â–µ–Ω–Ω'
        ]
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        predictions = []
        
        for text in texts:
            text_lower = text.lower()
            
            # –ü–æ–¥—Å—á–µ—Ç –æ–ø–∞—Å–Ω—ã—Ö –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —Å–ª–æ–≤
            dangerous_count = sum(1 for word in self.dangerous_keywords if word in text_lower)
            safe_count = sum(1 for word in self.safe_keywords if word in text_lower)
            
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if dangerous_count > safe_count and dangerous_count > 0:
                predictions.append(1)  # –û–ø–∞—Å–Ω—ã–π
            else:
                predictions.append(0)  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π
        
        return predictions


class AdvancedRuleBasedDetector:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª"""
    
    def __init__(self, name="–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å"):
        self.name = name
        # –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –≤–µ—Å–∞–º–∏
        self.dangerous_patterns = [
            (r'\b–¥–æ–ª–æ–π\b', 3),
            (r'\b—É–Ω–∏—á—Ç–æ–∂\w*\b', 3),
            (r'\b—Å–µ–∫—Ç–∞\b', 2),
            (r'\b—Ñ–∞–Ω–∞—Ç–∏–∫\w*\b', 2),
            (r'\b–ª–æ–∂—å\b', 1),
            (r'\b–æ–ø–∏—É–º\b', 2),
            (r'\b—á—É–º–∞\b', 2),
            (r'\b–æ—Ç—Ä–∞–≤–ª—è\w*\b', 2),
            (r'\b—Ä–∞–±—ã\b', 2),
            (r'\b–ª–∏—Ü–µ–º–µ—Ä\w*\b', 1),
            (r'\b–∑–æ–º–±–∏—Ä\w*\b', 2),
            (r'\b—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º\b', 3),
            (r'\b–Ω–µ–Ω–∞–≤–∏—Å—Ç\w*\b', 2),
            (r'\b—É–±–∏–≤–∞\w*\b', 3),
            (r'\b—Å–∞–¥–∏—Å—Ç\w*\b', 2),
            (r'\b–ø–∞—Ä–∞–∑–∏—Ç\w*\b', 2),
            (r'\b—Ä–µ–ø—Ä–µ—Å—Å–∏\w*\b', 2),
            (r'\b—Ç–æ—Ç–∞–ª–∏—Ç–∞—Ä\w*\b', 2)
        ]
        
        self.safe_patterns = [
            (r'\b–º–æ–ª–∏—Ç–≤–∞\b', 2),
            (r'\b–±–ª–∞–≥–æ—Å–ª–æ–≤\w*\b', 2),
            (r'\b–≤–µ—Ä–∞\b.*\b–ø–æ–º–æ–≥–∞\w*\b', 3),
            (r'\b–¥—É—Ö–æ–≤–Ω\w*\b', 1),
            (r'\b–ª—é–±–æ–≤\w*\b', 2),
            (r'\b–º–∏–ª–æ—Å–µ—Ä–¥–∏\w*\b', 2),
            (r'\b–Ω–∞–¥–µ–∂–¥\w*\b', 1),
            (r'\b—É—Ç–µ—à–µ–Ω–∏\w*\b', 1),
            (r'\b–º—É–¥—Ä–æ—Å—Ç\w*\b', 1),
            (r'\b–¥–æ–±—Ä–æ—Ç\w*\b', 1),
            (r'\b—á—É–¥–µ—Å–∞\b', 1)
        ]
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –≤–µ—Å–æ–≤—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏"""
        predictions = []
        
        for text in texts:
            text_lower = text.lower()
            
            # –ü–æ–¥—Å—á–µ—Ç –≤–µ—Å–æ–≤
            dangerous_score = 0
            safe_score = 0
            
            for pattern, weight in self.dangerous_patterns:
                if re.search(pattern, text_lower):
                    dangerous_score += weight
            
            for pattern, weight in self.safe_patterns:
                if re.search(pattern, text_lower):
                    safe_score += weight
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –≤–µ—Å–æ–≤
            if dangerous_score > safe_score + 1:  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥
                predictions.append(1)  # –û–ø–∞—Å–Ω—ã–π
            else:
                predictions.append(0)  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π
        
        return predictions


def analyze_test_dataset(df):
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    logger.info("üìä –ê–ù–ê–õ–ò–ó –¢–ï–°–¢–û–í–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    logger.info("="*50)
    
    total_samples = len(df)
    safe_count = (df['label'] == 0).sum()
    dangerous_count = (df['label'] == 1).sum()
    
    logger.info(f"üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {total_samples}")
    logger.info(f"‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã—Ö (label=0): {safe_count} ({safe_count/total_samples*100:.1f}%)")
    logger.info(f"üö® –û–ø–∞—Å–Ω—ã—Ö (label=1): {dangerous_count} ({dangerous_count/total_samples*100:.1f}%)")
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤
    text_lengths = df['text'].str.len()
    word_counts = df['text'].str.split().str.len()
    
    logger.info(f"\nüìù –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤:")
    logger.info(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {text_lengths.mean():.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"   –ú–µ–¥–∏–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞: {text_lengths.median():.1f} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Å–ª–æ–≤: {word_counts.mean():.1f}")
    
    logger.info("="*50)
    return True


def compare_models(test_df):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π"""
    logger.info("üÜö –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    logger.info("="*50)
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –º–æ–¥–µ–ª–∏
    simple_model = SimpleRuleBasedDetector("–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å (–ø—Ä–∞–≤–∏–ª–∞)")
    advanced_model = AdvancedRuleBasedDetector("–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞)")
    
    models = [simple_model, advanced_model]
    results = {}
    
    texts = test_df['text'].tolist()
    true_labels = test_df['label'].tolist()
    
    for model in models:
        logger.info(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É—é {model.name}...")
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        start_time = time.time()
        predictions = model.predict(texts)
        prediction_time = time.time() - start_time
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results[model.name] = {
            "predictions": predictions,
            "prediction_time": prediction_time
        }
        
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {prediction_time:.3f} —Å–µ–∫—É–Ω–¥")
        logger.info(f"üî¢ –ü–æ–ª—É—á–µ–Ω–æ {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    logger.info("="*50)
    
    for model_name, model_results in results.items():
        predictions = model_results["predictions"]
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(true_labels, predictions)
        
        logger.info(f"\nüéØ {model_name}:")
        logger.info(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f} ({accuracy*100:.1f}%)")
        logger.info(f"   –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {model_results['prediction_time']:.3f} —Å–µ–∫")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report = classification_report(
            true_labels, 
            predictions, 
            target_names=['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', '–û–ø–∞—Å–Ω—ã–π'],
            output_dict=True
        )
        
        logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
        logger.info(f"     Precision: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
        logger.info(f"     Recall: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
        logger.info(f"     F1-score: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
        
        logger.info(f"   –û–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
        logger.info(f"     Precision: {report['–û–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
        logger.info(f"     Recall: {report['–û–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
        logger.info(f"     F1-score: {report['–û–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(true_labels, predictions)
        logger.info(f"   –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
        logger.info(f"              –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
        logger.info(f"          –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π  –û–ø–∞—Å–Ω—ã–π")
        logger.info(f"   –ò—Å—Ç–∏–Ω–Ω–æ")
        logger.info(f"   –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π    {cm[0,0]:3d}      {cm[0,1]:3d}")
        logger.info(f"   –û–ø–∞—Å–Ω—ã–π       {cm[1,0]:3d}      {cm[1,1]:3d}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
    model_names = list(results.keys())
    predictions1 = results[model_names[0]]["predictions"]
    predictions2 = results[model_names[1]]["predictions"]
    
    agreement = sum(p1 == p2 for p1, p2 in zip(predictions1, predictions2))
    agreement_rate = agreement / len(predictions1)
    
    logger.info(f"\nü§ù –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π:")
    logger.info(f"   –°–æ–≤–ø–∞–¥–∞—é—â–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {agreement}/{len(predictions1)} ({agreement_rate*100:.1f}%)")
    
    # –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π
    disagreements = []
    for i, (p1, p2) in enumerate(zip(predictions1, predictions2)):
        if p1 != p2:
            disagreements.append({
                "index": i,
                "text": texts[i],
                model_names[0]: "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if p1 == 0 else "–û–ø–∞—Å–Ω—ã–π",
                model_names[1]: "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if p2 == 0 else "–û–ø–∞—Å–Ω—ã–π",
                "true_label": "–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π" if true_labels[i] == 0 else "–û–ø–∞—Å–Ω—ã–π"
            })
    
    if disagreements:
        logger.info(f"\nüîç –ü—Ä–∏–º–µ—Ä—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 5):")
        for i, disagreement in enumerate(disagreements[:5], 1):
            logger.info(f"   {i}. '{disagreement['text']}'")
            logger.info(f"      {disagreement[model_names[0]]} vs {disagreement[model_names[1]]} (–∏—Å—Ç–∏–Ω–∞: {disagreement['true_label']})")
    
    return results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üéØ –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–ï–¢–ï–ö–¶–ò–ò –û–°–ö–û–†–ë–õ–ï–ù–ò–Ø –ß–£–í–°–¢–í –í–ï–†–£–Æ–©–ò–•")
    logger.info("‚ú® –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –∏–º–∏—Ç–∞—Ü–∏–µ–π —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏")
    logger.info("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    labeled_test_file = "eval_modernbert_labeled - –õ–∏—Å—Ç1.csv"
    
    try:
        logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ {labeled_test_file}...")
        test_df = pd.read_csv(labeled_test_file)
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_df)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
    except FileNotFoundError:
        logger.error(f"‚ùå –§–∞–π–ª {labeled_test_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {labeled_test_file}: {e}")
        return
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not analyze_test_dataset(test_df):
        logger.error("‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞—Ç–∞—Å–µ—Ç–æ–º")
        return
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    results = compare_models(test_df)
    
    if results:
        logger.info("\nüéâ –°–†–ê–í–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        logger.info("‚ú® –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –ø—Ä–æ—Å—Ç–æ–π –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –º–æ–¥–µ–ª—è–º–∏")
        logger.info("üìù –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∏ –±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ModernBERT –º–æ–¥–µ–ª–µ–π")
    else:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏")


if __name__ == "__main__":
    main() 