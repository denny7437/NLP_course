#!/usr/bin/env python3
"""
–û–±—É—á–µ–Ω–∏–µ BERT –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —á—É–≤—Å—Ç–≤ –≤–µ—Ä—É—é—â–∏—Ö
(–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ ModernBERT –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ —Å DTensor)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from datasets import Dataset
import torch
import logging
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ReligiousContentDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–ª–∏–≥–∏–æ–∑–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ BERT"""
    
    def __init__(self):
        self.model_name = "DeepPavlov/rubert-base-cased"  # –ë–æ–ª–µ–µ –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å
        self.max_length = 256  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è GPU
        self.tokenizer = None
        self.model = None
        self.trainer = None
    
    def initialize_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        logger.info(f"–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {self.model_name}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=2
        )
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = self.model.to(device)
        logger.info(f"üñ•Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        logger.info("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def prepare_dataset(self, texts, labels):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        def tokenize_function(examples):
            return self.tokenizer(
                examples['text'],
                truncation=True,
                padding='max_length',
                max_length=self.max_length,
                return_tensors='pt'
            )
        
        dataset = Dataset.from_dict({
            'text': texts,
            'labels': labels
        })
        
        tokenized_dataset = dataset.map(tokenize_function, batched=True)
        return tokenized_dataset
    
    def compute_metrics(self, eval_pred):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)
        
        accuracy = accuracy_score(labels, predictions)
        report = classification_report(labels, predictions, output_dict=True, zero_division=0)
        
        return {
            'accuracy': accuracy,
            'f1_macro': report['macro avg']['f1-score'],
            'f1_weighted': report['weighted avg']['f1-score'],
            'precision_macro': report['macro avg']['precision'],
            'recall_macro': report['macro avg']['recall']
        }
    
    def train(self, train_texts, train_labels, val_texts, val_labels, epochs=5):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            self.initialize_model()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        train_dataset = self.prepare_dataset(train_texts, train_labels)
        val_dataset = self.prepare_dataset(val_texts, val_labels)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–ª–∞—Å—Å-–≤–µ—Å—ã –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        from sklearn.utils.class_weight import compute_class_weight
        class_weights = compute_class_weight(
            'balanced',
            classes=np.unique(train_labels),
            y=train_labels
        )
        class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}
        logger.info(f"üî¢ –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {class_weights_dict}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è (—É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        training_args = TrainingArguments(
            output_dir='./bert_religious_classifier_improved',
            num_train_epochs=epochs,
            per_device_train_batch_size=8,  # –£–º–µ–Ω—å—à–∏–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            per_device_eval_batch_size=8,
            gradient_accumulation_steps=2,  # –≠–º—É–ª–∏—Ä—É–µ–º batch_size=16
            warmup_steps=100,  # –ë–æ–ª—å—à–µ warmup —à–∞–≥–æ–≤
            weight_decay=0.01,
            logging_steps=10,
            eval_strategy="epoch",  # –û—Ü–µ–Ω–∫–∞ –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É
            save_strategy="no",  # –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            learning_rate=2e-5,  # –ú–µ–Ω—å—à–∏–π learning rate
            lr_scheduler_type="cosine",  # Cosine scheduler
            load_best_model_at_end=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            fp16=torch.cuda.is_available(),  # Mixed precision –µ—Å–ª–∏ GPU
            dataloader_num_workers=0,
            report_to=None,  # –û—Ç–∫–ª—é—á–∞–µ–º wandb
            seed=42,  # –§–∏–∫—Å–∏—Ä—É–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        )
        
        # –ö–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
        class WeightedTrainer(Trainer):
            def compute_loss(self, model, inputs, return_outputs=False):
                labels = inputs.get("labels")
                outputs = model(**inputs)
                logits = outputs.get('logits')
                
                # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
                loss_fct = torch.nn.CrossEntropyLoss(
                    weight=torch.tensor([class_weights_dict[0], class_weights_dict[1]], 
                                      dtype=torch.float32, device=logits.device)
                )
                loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))
                return (loss, outputs) if return_outputs else loss
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞ —Å –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –ø–æ—Ç–µ—Ä—å
        self.trainer = WeightedTrainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            compute_metrics=self.compute_metrics,
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        logger.info("–ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ...")
        try:
            train_result = self.trainer.train()
            logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å (—Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º contiguous tensor)
            logger.info("üíæ –°–æ—Ö—Ä–∞–Ω—è—é —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            
            # –î–µ–ª–∞–µ–º –≤—Å–µ —Ç–µ–Ω–∑–æ—Ä—ã contiguous –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            for name, param in self.model.named_parameters():
                if not param.is_contiguous():
                    param.data = param.data.contiguous()
            
            self.trainer.save_model()
            self.tokenizer.save_pretrained('./bert_religious_classifier_improved')
            logger.info("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            
            return train_result
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            return None
    
    def predict(self, texts):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU"""
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(device)
        self.model.eval()
        predictions = []
        
        with torch.no_grad():
            for text in texts:
                inputs = self.tokenizer(
                    text,
                    return_tensors="pt",
                    truncation=True,
                    padding='max_length',
                    max_length=self.max_length
                )
                
                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                inputs = {k: v.to(device) for k, v in inputs.items()}
                
                outputs = self.model(**inputs)
                predicted_class = torch.argmax(outputs.logits, dim=-1)
                predictions.append(predicted_class.item())
        
        return predictions
    
    def evaluate_on_test(self, test_texts, test_labels):
        """–û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        predictions = self.predict(test_texts)
        
        accuracy = accuracy_score(test_labels, predictions)
        report = classification_report(
            test_labels, 
            predictions, 
            target_names=['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π', '–û–ø–∞—Å–Ω—ã–π'],
            output_dict=True
        )
        
        return accuracy, predictions, report


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üéØ –û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ BERT –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —á—É–≤—Å—Ç–≤ –≤–µ—Ä—É—é—â–∏—Ö")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        logger.info(f"üöÄ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_name}")
        logger.info(f"üíæ –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        logger.info("üñ•Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è CPU")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info("üìä –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ...")
    df = pd.read_csv("train - –õ–∏—Å—Ç1.csv")
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    class_distribution = df['label'].value_counts().sort_index()
    logger.info("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    logger.info(f"  –ö–ª–∞—Å—Å 0 (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π): {class_distribution[0]} ({class_distribution[0]/len(df)*100:.1f}%)")
    logger.info(f"  –ö–ª–∞—Å—Å 1 (–æ–ø–∞—Å–Ω—ã–π): {class_distribution[1]} ({class_distribution[1]/len(df)*100:.1f}%)")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df['text'].tolist()
    y = df['label'].tolist()
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.15, random_state=42, stratify=y_temp
    )
    
    logger.info(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)}")
    logger.info(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_val)}")
    logger.info(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
    detector = ReligiousContentDetector()
    
    # –û–±—É—á–µ–Ω–∏–µ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    train_result = detector.train(X_train, y_train, X_val, y_val, epochs=5)
    
    if train_result is not None:
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        logger.info("üìä –û—Ü–µ–Ω–∏–≤–∞—é –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        accuracy, predictions, report = detector.evaluate_on_test(X_test, y_test)
        
        logger.info(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        logger.info(f"\n–î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
        logger.info(f"–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
        logger.info(f"  Precision: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
        logger.info(f"  Recall: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
        logger.info(f"  F1-score: {report['–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
        
        logger.info(f"–û–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:")
        logger.info(f"  Precision: {report['–û–ø–∞—Å–Ω—ã–π']['precision']:.3f}")
        logger.info(f"  Recall: {report['–û–ø–∞—Å–Ω—ã–π']['recall']:.3f}")
        logger.info(f"  F1-score: {report['–û–ø–∞—Å–Ω—ã–π']['f1-score']:.3f}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(y_test, predictions)
        logger.info(f"\nüîç –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
        logger.info(f"             –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ")
        logger.info(f"         –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π  –û–ø–∞—Å–Ω—ã–π")
        logger.info(f"–ò—Å—Ç–∏–Ω–Ω–æ")
        logger.info(f"–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π    {cm[0,0]:3d}      {cm[0,1]:3d}")
        logger.info(f"–û–ø–∞—Å–Ω—ã–π       {cm[1,0]:3d}      {cm[1,1]:3d}")
        
        logger.info("\nüéâ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        logger.info("‚ú® BERT –æ–±—É—á–µ–Ω –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è —á—É–≤—Å—Ç–≤ –≤–µ—Ä—É—é—â–∏—Ö")
    else:
        logger.error("‚ùå –û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å")


if __name__ == "__main__":
    main() 